{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### For Table of Contents: \n",
    "#### https://github.com/minrk/ipython_extensions\n",
    "\n",
    "```\n",
    "curl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.js > $(ipython locate)/nbextensions/toc.js\n",
    "curl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.css > $(ipython locate)/nbextensions/toc.css\n",
    "\n",
    "echo '\n",
    "$([IPython.events]).on(\"app_initialized.NotebookApp\", function () {\n",
    "    IPython.load_extensions(\"toc\");\n",
    "});' >> $(ipython locate)/profile_default/static/custom/custom.js\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GPDB Demo Setup\n",
    "\n",
    "### Note:  This notebook is always evolving.  It will be updated periodically to include nifty tips/tricks.\n",
    "\n",
    "1. Create a directory ```/home/gpadmin/bds``` on the master node.\n",
    "2. Put the following files (found on Google drive) into ```/home/gpadmin/bds```:\n",
    "  - https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
    "  - crimes-2001-present.csv.tar.gz (unzip via ```tar -xvf crimes-2001-present.csv.tar.gz```)\n",
    "  - ```cp crimes-2001-present.csv crimes-all.csv```\n",
    "  - gpdemo-dwbi.sql\n",
    "  - resource_queue (uzip via `tar -xvf resource_queues.tar`)\n",
    "  - weather folder (contains several .csv files for loading)\n",
    "3. Use Appendix A of this script to create two custom views that show storage and compression data.  \n",
    "4. Use Appendix B of this script to create functions that will be used in this script\n",
    "5. Use Appendix C of this script to make this dataset larger.  Recommend 50M records for demo on DCA.\n",
    "6. ~~Use a tool like pgAdmin3 or DbVisualizer to execute the statements in this script during the demo.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "-- Connect to the dca and database through a terminal window.\n",
    "ssh gpadmin@10.68.128.7  --supply password if prompted (changeme)\n",
    "gpstate; gpstate -e; gpstate -m  -- check the status of the database and the mirrors\n",
    "\"\"\";\n",
    "\n",
    "\"\"\"\n",
    "-- 1. Using the commmand line.\n",
    "psql -d postgres; \n",
    "\\l  -- list databases\n",
    "create database bds; \\c bds;\n",
    "\\d  -- list tables\n",
    "\\?, \\h, \\h vacuum\n",
    "\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install ipython-sql:\n",
    "```\n",
    "    pip install ipython-sql\n",
    "```\n",
    "\n",
    "#### Adjust path to allow psycopg2 to install:\n",
    "```\n",
    "    PATH=$PATH:/path/to/pg_config pip install psycopg2 pip install psycopg2\n",
    "```\n",
    "\n",
    "#### may need to do this also:\n",
    "``` \n",
    "    install_name_tool -change libcrypto.1.0.0.dylib \\\n",
    "    /Users/kdunn/anaconda/lib/libcrypto.1.0.0.dylib \\\n",
    "    /Users/kdunn/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so\n",
    "```\n",
    "\n",
    "#### and the same for libssl.1.0.0.dylib:\n",
    "``` \n",
    "    install_name_tool -change libssl.1.0.0.dylib \\\n",
    "    /Users/kdunn/anaconda/lib/libssl.1.0.0.dylib \\\n",
    "    /Users/kdunn/anaconda/lib/python2.7/site-packages/psycopg2/_psycopg.so\n",
    "```\n",
    "\n",
    "Reference: https://github.com/catherinedevlin/ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Connected: gpadmin@gpadmin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://gpadmin@192.168.69.145/gpadmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the table to hold the crimes data from data.gov.  we already know the layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "291058 rows affected.\n",
      "1 rows affected.\n",
      "0 rows affected.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "drop table if exists crimes;\n",
    "CREATE TABLE crimes\n",
    "(\n",
    "  id int\n",
    " ,case_number varchar (20)\n",
    " ,crime_date timestamp\n",
    " ,block varchar(50)\n",
    " ,IUCR varchar(10)\n",
    " ,primary_type varchar(50)\n",
    " ,description varchar(75)\n",
    " ,location_desc varchar (75)\n",
    " ,arrest boolean\n",
    " ,domestic boolean\n",
    " ,beat varchar(7)\n",
    " ,district varchar(7)\n",
    " ,ward smallint\n",
    " ,community_area varchar(10)\n",
    " ,fbi_code varchar(5)\n",
    " ,x_coord float\n",
    " ,y_coord float\n",
    " ,crime_year smallint\n",
    " ,record_update_date timestamp\n",
    " ,latitude float\n",
    " ,longitude float\n",
    " ,location varchar (60)\n",
    ")\n",
    "distributed by (id);\n",
    "\n",
    "drop table if exists weather_data;\n",
    "CREATE TABLE weather_data\n",
    "(\n",
    "  CST timestamp\n",
    "  ,MaxTemperatureF int\n",
    "  ,MeanTemperature int\n",
    "  ,MinTemperatureF int\n",
    "  ,MaxDewPointF float\n",
    "  ,MeanDewPointF float\n",
    "  ,MinDewpointF float\n",
    "  ,MaxHumidity float\n",
    "  ,MeanHumidity float\n",
    "  ,MinHumidity float\n",
    "  ,MaxSeaLevelPressureIn float\n",
    "  ,MeanSeaLevelPressureIn float\n",
    "  ,MinSeaLevelPressureIn float\n",
    "  ,MaxVisibilityMiles float\n",
    "  ,MeanVisibilityMiles float\n",
    "  ,MinVisibilityMiles float\n",
    "  ,MaxWindSpeedMPH float\n",
    "  ,MeanWindSpeedMPH float\n",
    "  ,MaxGustSpeedMPH float\n",
    "  ,PrecipitationIn varchar(20)\n",
    "  , CloudCover float\n",
    "  , Events varchar(50)\n",
    "  , WindDirDegrees float);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use the 'COPY' command in the command line to bulk-load data via the master server.\n",
    "timing on (note, psycopg2 isn't a fan the timing option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "COPY crimes FROM '/home/gpadmin/chicagoCrimes-all-2001-July262015.csv' \n",
    "CSV HEADER LOG ERRORS INTO err_crimes KEEP SEGMENT REJECT LIMIT 50 ROWS;  -- (13 secs.)\n",
    "\n",
    "select count(*) total_records from crimes;\n",
    "select * from err_crimes;\n",
    "\n",
    "truncate table crimes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallel loading with gpfdist  \n",
    "### Kill and restart the gpfdist utility on the database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "ps ax | grep gpfdist\n",
    "pkill -9 gpfdist\n",
    "gpfdist -d /home/gpadmin/bds/ -p 8081 -l /home/gpadmin/bds/gpfdist.log &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an external table that 'points' to the source file.\n",
    "NOTE:  can load multiple zipped files in parallel without unzipping.  gpfdist://mdw:8081/*.gz'   VERY FAST!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop external table if exists ext_crimes;\n",
    "drop external table if exists ext_weather_data;\n",
    "\n",
    "create external table ext_crimes (like crimes) \n",
    "location ('gpfdist://mdw:8081/crimes_all.csv') \n",
    "format 'csv' (header);\n",
    "\n",
    "create external table ext_weather_data (like weather_data) \n",
    "location ('gpfdist://mdw:8081/weather/*.csv') \n",
    "format 'csv' (header);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the data to see there are no tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select count(*) total_recs from crimes;\n",
    "select count(*) total_recs from weather_data;\n",
    "\n",
    "-- (35 secs, only works if the file is unzipped)\n",
    "select count(*) total_recs from ext_crimes;  \n",
    "\n",
    "select count(*) total_recs from ext_weather_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data from the source file (external table) into the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- (60M recs, 45 seconds on 1/4 rack DCA; 5 minutes on a single-node VM)\n",
    "insert into crimes (select * from ext_crimes);  \n",
    "\n",
    "insert into weather_data (select * from ext_weather_data);\n",
    "select count(*) total_recs from crimes;\n",
    "select count(*) total_recs from weather_data;\n",
    "select * from crimes limit 10;\n",
    "select * from weather_data order by 1 desc limit 100;\n",
    "select distinct primary_type from crimes;\n",
    "select distinct events from weather_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we'll do a bit more stress-testing down below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data load from external web source - Worldwide earthquakes for the last 7 days  \n",
    "https://explore.data.gov/Geography-and-Environment/Worldwide-M1-Earthquakes-Past-7-Days/7tag-iwnu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS wwearthquakes_lastwk;\n",
    "CREATE TABLE wwearthquakes_lastwk (\n",
    "    time TEXT, \n",
    "    latitude numeric, \n",
    "    longitude numeric, \n",
    "    depth numeric, \n",
    "    mag numeric, \n",
    "    mag_type varchar (10),\n",
    "    NST integer, \n",
    "    gap numeric, \n",
    "    dmin numeric, \n",
    "    rms text, \n",
    "    net text, \n",
    "    id text, \n",
    "    updated TEXT, \n",
    "    place varchar(150), \n",
    "    type varchar(50)\n",
    ")\n",
    "DISTRIBUTED BY (time);\n",
    "\n",
    "DROP EXTERNAL TABLE IF EXISTS ext_wwearthquakes_lastwk;\n",
    "\n",
    "create external web table ext_wwearthquakes_lastwk (like wwearthquakes_lastwk) \n",
    "-- defining an OS command to execute\n",
    "Execute 'wget -qO - http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_week.csv' \n",
    "ON MASTER\n",
    "Format 'CSV' (HEADER)\n",
    "Segment Reject limit 300;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and browse the data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into wwearthquakes_lastwk select * from ext_wwearthquakes_lastwk;\n",
    "select count(*) total_records from wwearthquakes_lastwk;\n",
    "select * from wwearthquakes_lastwk order by 1 desc limit 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using a Sequence during load.  \n",
    "### Note the 'blocks of values' assigned;  the master is the single source of truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "drop sequence if exists myseq;\n",
    "create sequence myseq start 300 cache 1000;\n",
    "\n",
    "drop table if exists crimes_seq;\n",
    "create table crimes_seq as (select nextval('myseq') \n",
    "                            as my_key, id, ward, primary_type \n",
    "                            from crimes limit 100);\n",
    "\n",
    "select * from crimes_seq order by 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test pl/pgsql functions.  \n",
    "### Use Appendix B or `psql -f /home/gpadmin/bds/xxx.sql` to build them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select buildDateDim (date '2001-01-01', date '2014-12-31'); \n",
    "select * from dim_date order by 1 limit 100;\n",
    "select buildTimeDim(); select * from dim_time order by 1;\n",
    "select myfunc (3, 'Hello');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best practice to do `VACUUM & ANALYZE` routinely and after big loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "vacuum analyze crimes;  \n",
    "vacuum analyze weather_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Data Distribution, Partitioning, and Polymorphic Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a table with a bad distribution key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes_bad_key;\n",
    "create table crimes_bad_key (like crimes) distributed by (arrest);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into the table and browse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done.\n",
      "0 rows affected.\n",
      "1 rows affected.\n",
      "(psycopg2.ProgrammingError) schema \"gp_toolkit\" does not exist\n",
      "LINE 5: select * from gp_toolkit.gp_skew_coefficients ;\n",
      "                      ^\n",
      " [SQL: \"-- View skew.  Could also be done live in Command Center in real time.\\n-- Look at 'gp_skew_coefficients' in gp_toolkit.  Lower number is better.\\n-- Look at 'gp_skew_idle_fractions' in gp_toolkit.  0.1 = 10%% idle, which is ok.  0.5 = 50%%, which is bad.\\n\\nselect * from gp_toolkit.gp_skew_coefficients ;\"]\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "-- 175 seconds on a 1/4 rack\n",
    "insert into crimes_bad_key (select * from crimes);  \n",
    "select count(*) total_records from crimes_bad_key;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View skew.  Could also be done live in Command Center in real time.\n",
    "#### Look at 'gp_skew_coefficients' in gp_toolkit.  Lower number is better.\n",
    "#### Look at 'gp_skew_idle_fractions' in gp_toolkit.  0.1 = 10% idle, which is ok.  0.5 = 50%, which is bad\n",
    "#### TODO (doesn't work in HAWQ) select * from gp_toolkit.gp_skew_coefficients ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A binary key will result in highly skewed data load (compare to crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>arrest</th>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select distinct (arrest) from crimes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a partitioned table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "drop table if exists crimes_part;\n",
    "create table crimes_part(\n",
    "  id int\n",
    " ,case_number varchar (20)\n",
    " ,crime_date timestamp\n",
    " ,block varchar(50)\n",
    " ,IUCR varchar(10)\n",
    " ,primary_type varchar(50)\n",
    " ,description varchar(75)\n",
    " ,location_desc varchar (75)\n",
    " ,arrest boolean\n",
    " ,domestic boolean\n",
    " ,beat varchar(7)\n",
    " ,district varchar(7)\n",
    " ,ward smallint\n",
    " ,community_area varchar(10)\n",
    " ,fbi_code varchar(5)\n",
    " ,x_coord float\n",
    " ,y_coord float\n",
    " ,crime_year smallint\n",
    " ,record_update_date timestamp\n",
    " ,latitude float\n",
    " ,longitude float\n",
    " ,location varchar (60)\n",
    ")\n",
    "\n",
    "distributed by (id)\n",
    "partition by list (primary_type) \n",
    "    (partition p1 values ('ROBBERY'), \n",
    "     partition p2 values ('BURGLARY'), \n",
    "     partition p3 values ('THEFT'), \n",
    "     partition p4 values ('PROSTITUTION'),\n",
    "     partition p5 values ('RITUALISM'), \n",
    "     partition p6 values ('NARCOTICS'), \n",
    "     partition p7 values ('KIDNAPPING'), \n",
    "     partition p8 values ('INTIMIDATION'),\n",
    "     partition p9 values ('BATTERY'), \n",
    "     partition p10 values ('ASSAULT'), \n",
    "     partition p11 values ('ARSON'), \n",
    "     partition p12 values ('STALKING'),\n",
    "     partition p13 values ('GAMBLING'), \n",
    "     partition p14 values ('DOMESTIC VIOLENCE'), \n",
    "     partition p15 values ('WEAPONS VIOLATION'), \n",
    "     partition p16 values ('DECEPTIVE PRACTICE'),\n",
    "     default partition other );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into the partitioned table and browse the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows affected.\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>total_records</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>0</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(0L,)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "insert into crimes_part (select * from crimes);  -- (15 secs.)\n",
    "select count(*) total_records from crimes_part;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate an explain plan\n",
    "### See query cost on the non-partitioned table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>QUERY PLAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sort  (cost=0.00..3.68 rows=1 width=173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Sort Key: id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;-&gt;  Gather Motion 1:1  (slice1; segments: 1)  (cost=0.00..2.68 rows=1 width=173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;  Table Scan on crimes  (cost=0.00..1.51 rows=1 width=173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Filter: primary_type::text = ANY (ARRAY['NARCOTICS'::character varying, 'GAMBLING'::character varying]::text[])</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'Sort  (cost=0.00..3.68 rows=1 width=173)',),\n",
       " (u'  Sort Key: id',),\n",
       " (u'  ->  Gather Motion 1:1  (slice1; segments: 1)  (cost=0.00..2.68 rows=1 width=173)',),\n",
       " (u'        ->  Table Scan on crimes  (cost=0.00..1.51 rows=1 width=173)',),\n",
       " (u\"              Filter: primary_type::text = ANY (ARRAY['NARCOTICS'::character varying, 'GAMBLING'::character varying]::text[])\",)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select crimes.*\n",
    "from crimes\n",
    "where primary_type in ('NARCOTICS', 'GAMBLING')\n",
    "order by id;  -- (3.4 secs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate an explain plan to see the cost of the query on the partitioned table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>QUERY PLAN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Sort  (cost=0.00..5.03 rows=1 width=176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Sort Key: crimes_part.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;-&gt;  Gather Motion 1:1  (slice1; segments: 1)  (cost=0.00..4.03 rows=1 width=176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;  Sequence  (cost=0.00..2.86 rows=1 width=176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;  Result  (cost=0.00..1.52 rows=1 width=176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;  Function Scan on gp_partition_expansion  (cost=10.00..100.00 rows=100 width=4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&gt;  Dynamic Table Scan on crimes_part (partIndex: 0)  (cost=0.00..2.86 rows=1 width=176)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Filter: primary_type::text = ANY (ARRAY['NARCOTICS'::character varying, 'GAMBLING'::character varying]::text[])</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(u'Sort  (cost=0.00..5.03 rows=1 width=176)',),\n",
       " (u'  Sort Key: crimes_part.id',),\n",
       " (u'  ->  Gather Motion 1:1  (slice1; segments: 1)  (cost=0.00..4.03 rows=1 width=176)',),\n",
       " (u'        ->  Sequence  (cost=0.00..2.86 rows=1 width=176)',),\n",
       " (u'              ->  Result  (cost=0.00..1.52 rows=1 width=176)',),\n",
       " (u'                    ->  Function Scan on gp_partition_expansion  (cost=10.00..100.00 rows=100 width=4)',),\n",
       " (u'              ->  Dynamic Table Scan on crimes_part (partIndex: 0)  (cost=0.00..2.86 rows=1 width=176)',),\n",
       " (u\"                    Filter: primary_type::text = ANY (ARRAY['NARCOTICS'::character varying, 'GAMBLING'::character varying]::text[])\",)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select crimes_part.*\n",
    "from crimes_part\n",
    "where primary_type in ('NARCOTICS', 'GAMBLING')\n",
    "order by id; -- (1 sec.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Storage and Compression.  \n",
    "### Create the table that's column-oriented with quickLZ compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes_qlz;\n",
    "create table crimes_qlz (like crimes)\n",
    "with (appendonly=true, orientation=column, compresstype=quicklz)\n",
    "partition by list (primary_type) \n",
    "    (partition p1 values ('ROBBERY'), \n",
    "     partition p2 values ('BURGLARY'), \n",
    "     partition p3 values ('THEFT'), \n",
    "     partition p4 values ('PROSTITUTION'),\n",
    "     partition p5 values ('RITUALISM'), \n",
    "     partition p6 values ('NARCOTICS'), \n",
    "     partition p7 values ('KIDNAPPING'), \n",
    "     partition p8 values ('INTIMIDATION'),\n",
    "     partition p9 values ('BATTERY'), \n",
    "     partition p10 values ('ASSAULT'), \n",
    "     partition p11 values ('ARSON'), \n",
    "     partition p12 values ('STALKING'),\n",
    "     partition p13 values ('GAMBLING'), \n",
    "     partition p14 values ('DOMESTIC VIOLENCE'), \n",
    "     partition p15 values ('WEAPONS VIOLATION'), \n",
    "     partition p16 values ('DECEPTIVE PRACTICE'),\n",
    "     default partition other );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into crimes_qlz (select * from crimes);  --12 secs.\n",
    "select count(*) total_records from crimes_qlz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the explain plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select crimes_qlz.*\n",
    "from crimes_qlz\n",
    "where primary_type in ('NARCOTICS', 'GAMBLING')\n",
    "order by id; -- (1 sec.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table with zLib, level=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes_zlib;\n",
    "create table crimes_zlib (like crimes)\n",
    "with (appendonly=true, orientation=column, compresstype=zlib, compresslevel=5)\n",
    "partition by list (primary_type) \n",
    "    (partition p1 values ('ROBBERY'), \n",
    "     partition p2 values ('BURGLARY'), \n",
    "     partition p3 values ('THEFT'), \n",
    "     partition p4 values ('PROSTITUTION'),\n",
    "     partition p5 values ('RITUALISM'), \n",
    "     partition p6 values ('NARCOTICS'), \n",
    "     partition p7 values ('KIDNAPPING'), \n",
    "     partition p8 values ('INTIMIDATION'),\n",
    "     partition p9 values ('BATTERY'), \n",
    "     partition p10 values ('ASSAULT'), \n",
    "     partition p11 values ('ARSON'), \n",
    "     partition p12 values ('STALKING'),\n",
    "     partition p13 values ('GAMBLING'), \n",
    "     partition p14 values ('DOMESTIC VIOLENCE'), \n",
    "     partition p15 values ('WEAPONS VIOLATION'), \n",
    "     partition p16 values ('DECEPTIVE PRACTICE'),\n",
    "     default partition other );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into crimes_zlib (select * from crimes);  --(25 secs.)\n",
    "select count(*) as total_recs from crimes_zlib;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the explain plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select crimes_zlib.*\n",
    "from crimes_zlib\n",
    "where primary_type in ('NARCOTICS', 'GAMBLING')\n",
    "order by id; -- (1 sec.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. With all the same counts, look at the size of tables  \n",
    "### Note:  No Indexes!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT tabs.nspname AS schema_name\n",
    ",      COALESCE(parts.tablename, tabs.relname) AS table_name\n",
    ",      ROUND(SUM(sotaidtablesize)/1024/1024/1024,3) AS table_GB\n",
    ",      ROUND(SUM(sotaididxsize)/1024/1024/1024,3) AS index_GB\n",
    "FROM   gp_toolkit.gp_size_of_table_and_indexes_disk sotd\n",
    ",     (SELECT c.oid, c.relname, n.nspname\n",
    "       FROM   pg_class c\n",
    "       ,      pg_namespace n\n",
    "       WHERE  n.oid = c.relnamespace\n",
    "       AND    c.relname NOT LIKE '%_err'\n",
    "      )tabs\n",
    "LEFT JOIN pg_partitions parts\n",
    "ON     tabs.nspname = parts.schemaname\n",
    "AND    tabs.relname = parts.partitiontablename\n",
    "WHERE  sotd.sotaidoid = tabs.oid and tabs.nspname = 'public'\n",
    "GROUP BY tabs.nspname, COALESCE(parts.tablename, tabs.relname)\n",
    "ORDER BY 1 desc,2;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View this customized view for table, storage, and compression characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select * from v_gp_table_storage2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Swapping partitions  \n",
    "### Create a table that represents one of the partitions and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes_p0;\n",
    "create table crimes_p0 (like crimes_part) \n",
    "with (appendonly=true, compresstype=quicklz, orientation=column);\n",
    "\n",
    "insert into crimes_p0 (select * from crimes where primary_type = 'NARCOTICS');\n",
    "select count(*) total_records from crimes_p0;\n",
    "\n",
    "-- swap the partition in the table with our 'latest' table.  \n",
    "-- Note in pdAdmin3 the table layout.  The partition is now different from others.\n",
    "alter table crimes_part EXCHANGE PARTITION FOR ('NARCOTICS') WITH TABLE crimes_p0;\n",
    "select count(*) total_records from crimes_part where primary_type = 'NARCOTICS';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (Optional) Perform garbage-collection and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "vacuum analyze crimes;\n",
    "vacuum analyze crimes_part;\n",
    "vacuum analyze crimes_qlz;\n",
    "vacuum analyze crimes_zlib;\n",
    "vacuum analyze weather_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III BI/ETL Interoperability\n",
    "\n",
    "### Pentaho integration video in gDrive: `gpdb-pentaho.mov`\n",
    "\n",
    "- create/view a database connection.\n",
    "- create/view a new transformation mapping\n",
    "- source = .csv (same as before); target = gpdb\n",
    "- execute the ETL transformation via sh spoon.sh --file xxx.ktr\n",
    "- note:  it creates the YAML file and .dat file for gpload.  can also have it just create the YAML and .dat file w/o executing\n",
    "- more crimes.yaml; more crimes.dat\n",
    "- call the gpload utility (gpload -f filename.cfg) to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "select count(*) total_recs from cms;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: CONNECT GPDB TO HDFS VIA GPHDFS PROTOCOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV - Advanced SQL and Analytics\n",
    "### Windowing Functions and Analytics via Madlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stress test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select\n",
    "  to_char(a.crime_date, 'yyyy')\n",
    "  ,a.primary_type\n",
    "  ,count(a.primary_type)\n",
    "from crimes a\n",
    "join (select to_char(b.crime_date, 'yyyy'), b.primary_type, count(b.primary_type)\n",
    "      from crimes b\n",
    "      where to_char(crime_date, 'yyyy') = to_char(now() - interval '1 year', 'yyyy')\n",
    "      group by 1,2\n",
    "      order by count(b.primary_type) desc\n",
    "      limit 5) c on a.primary_type=c.primary_type\n",
    "where to_char(crime_date, 'yyyy') in (to_char(now(), 'yyyy'), to_char(now() - interval '1 year', 'yyyy'))\n",
    "group by 1,2\n",
    "order by 2,1 desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select primary_type, arrest, year_month, month_name, day_name, count(*)\n",
    "from crimes a \n",
    "inner join dim_date b on to_char(a.crime_date, 'yyyy-mm-dd') = to_char(b.date_value, 'yyyy-mm-dd')\n",
    "group by 1,2,3,4,5\n",
    "limit 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select primary_type, arrest, year_month, month_name, day_name, count(*)\n",
    "from crimes_part a \n",
    "inner join dim_date b on to_char(a.crime_date, 'yyyy-mm-dd') = to_char(b.date_value, 'yyyy-mm-dd')\n",
    "where a.primary_type = 'NARCOTICS'\n",
    "group by 1,2,3,4,5\n",
    "limit 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WINDOWING FUNCTION.  RUNNING COUNT OF CRIMES BY DISTRICT. ADJUST TO INCLUDE MONTH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select district, count(distinct id)  ,\n",
    "       sum(count(distinct id)) over (order by district, count(distinct id) desc) as running_sum\n",
    "from crimes\n",
    "where district in ('003', '014', '031') \n",
    "group by district;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM madlib.summary( 'bds.crimes', \n",
    "                              'bds.crimes_summary', \n",
    "                              'block,beat,ward,primary_type', \n",
    "                              'arrest', \n",
    "                              TRUE, \n",
    "                              TRUE, \n",
    "                              NULL, \n",
    "                              5, \n",
    "                              FALSE\n",
    "                            );\n",
    "select * from crimes_summary;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression: \n",
    "(need to train a model, then run a 2nd time to determine what the dependent variables are.  Used for Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT madlib.linregr_train( 'crimes',\n",
    "                             'crimes_linregr',\n",
    "                             'arrest_flag::int',\n",
    "                             'ARRAY[1, block, ward, primary_type, beat]'\n",
    "                           );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix between all the numeric columns in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select * from example_data;\n",
    "SELECT madlib.correlation( 'example_data',\n",
    "                           'example_data_output'\n",
    "                         );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select * from example_data_output order by column_position;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V - Backup Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPDUMP is a parallelized backup utility.\n",
    "Usage:\n",
    "```'gpcrondump -x ..'  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGDUMP is a utility for backing up data when you know it'll be restored to a different number of segments.\n",
    "```pg_dump -t crimes_seq bds > backup1.sql;```  \n",
    "- utility creates one file on the server.  Loaded via COPY.\n",
    "\n",
    "```pg_dump --column-inserts -t crimes_seq bds > backup2.sql``` \n",
    "- option to include all insert statements.\n",
    "\n",
    "```pg_restore``` is used to restore the database.  Has many options as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a writable external tables for controlled backup.\n",
    "#### Create an external table that we can write data to (but really its a file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop external table if exists crimes_export;\n",
    "create writable external table crimes_export (like crimes)\n",
    "location ('gpfdist://mdw:8081/crimes_backup.csv')\n",
    "format 'csv' (delimiter ',' null '');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data into the external table (flat file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "insert into crimes_export (select * from crimes where crime_year = 2014);\n",
    "\n",
    "-- you get an error, but you can see the file in the directory.\n",
    "select count(*) from crimes_export; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-load the data from the backup.  Start with creating an external table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql \n",
    "\n",
    "drop external table if exists crimes_backup;\n",
    "create external table crimes_backup (like crimes)\n",
    "location ('gpfdist://mdw:8081/crimes_backup.csv')\n",
    "format 'csv' (delimiter ',' null '');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select count(*) total_records from crimes_backup;\n",
    "select count(*) total_records from crimes;\n",
    "insert into crimes (select * from crimes_backup);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI - Hadoop and Hawq\n",
    "1. Perform loading of same data into Hadoop\n",
    "  - hadoop fs -put\n",
    "  - HUE\n",
    "  - ETL Program\n",
    "  - Internal/external tables in Hive & Hawq\n",
    "2. SQL Capacbility (Hive vs. Hawq)\n",
    "3. SQL Performance (Hive vs. Hawq vs. GPDB)\n",
    "4. Attempt an update on a Hawq table\n",
    "5. Store data in Parquet format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%sql <<hive uri>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Below will automatically create the directory in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE crimes;\n",
    "CREATE TABLE crimes (\n",
    "     id string\n",
    "    ,case_number string\n",
    "    ,crime_date string\n",
    "    ,block string\n",
    "    ,IUCR string\n",
    "    ,primary_type string\n",
    "    ,description string\n",
    "    ,location_desc string\n",
    "    ,arrest_flag string\n",
    "    ,domestic_flag string\n",
    "    ,beat string\n",
    "    ,district string\n",
    "    ,ward string\n",
    "    ,community_area string\n",
    "    ,fbi_code string\n",
    "    ,x_coordinate string\n",
    "    ,y_coordinate string\n",
    "    ,year string\n",
    "    ,rec_date string\n",
    "    ,latitude string\n",
    "    ,longitude string\n",
    ")\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' \n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/bmg/crimes/';  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into Hive (from Hive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "--(alternative to hadoop fs -put ...)\n",
    "LOAD DATA LOCAL INPATH '/home/gpadmin/bds/crimes.csv.tar.gz' \n",
    "OVERWRITE INTO TABLE crimes;\n",
    "\n",
    "select * from crimes limit 1;\n",
    "select count(*) from crimes;\n",
    "\n",
    "select year, description, count(*) total_crimes\n",
    "from crimes\n",
    "where year in ('2011', '2012') and primary_type in ('CRIMINAL DAMAGE')\n",
    "group by year, description\n",
    "order by year, description\n",
    "limit 30;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can't support ANSI-Standard SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select year, description, count(*) total_crimes\n",
    "from crimes\n",
    "group by 1,2\n",
    "order by 3, 1 desc\n",
    "limit 30;\n",
    "\n",
    "with a as (select count(*) from crimes)\n",
    "select * from a;\n",
    "\n",
    "select * from crimes where primary_type not in \n",
    "(select primary_type from crimes where primary_type in ('THEFT'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hawq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%sql postgresql://gpadmin@localhost/hawqDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes;\n",
    "CREATE TABLE crimes (\n",
    "     id varchar (15)\n",
    "    ,case_number varchar(50)\n",
    "    ,crime_date varchar(50)\n",
    "    ,block varchar(75)\n",
    "    ,IUCR varchar(75)\n",
    "    ,primary_type varchar(75)\n",
    "    ,description varchar(100)\n",
    "    ,location_desc varchar(125)\n",
    "    ,arrest_flag varchar(20)\n",
    "    ,domestic_flag varchar(20)\n",
    "    ,beat varchar(15)\n",
    "    ,district varchar(15)\n",
    "    ,ward varchar(15)\n",
    "    ,community_area varchar(15)\n",
    "    ,fbi_code varchar(15)\n",
    "    ,x_coordinate varchar(20)\n",
    "    ,y_coordinate varchar(20)\n",
    "    ,year char(4)\n",
    "    ,rec_date varchar(20)\n",
    "    ,latitude varchar(20)\n",
    "    ,longitude varchar(20)\n",
    ") \n",
    "DISTRIBUTED by (id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rejects errors, does not put file into hdfs directory\n",
    "\n",
    "(rejected errors + loaded records) has a difference of 3 between hawq and hive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "zcat crimes.csv.tar.gz | psql -c \"COPY crimes FROM STDIN CSV DELIMITER ',' SEGMENT REJECT LIMIT 100000;\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANSI SQL Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select year, description, count(*) total_crimes\n",
    "from crimes\n",
    "where year in ('2011', '2012') and primary_type in ('CRIMINAL DAMAGE')\n",
    "group by 1,2\n",
    "order by 1,2\n",
    "limit 30;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub-select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "select * from crimes \n",
    "where primary_type not in (select primary_type from crimes where primary_type in ('THEFT')) \n",
    "limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### window functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "explain\n",
    "select district, count(distinct ward)  ,\n",
    "       sum(count(distinct ward)) over (order by district, count(distinct ward) desc) \n",
    "as running_sum\n",
    "from crimes\n",
    "where district in ('001', '014', '031') \n",
    "group by district;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop sequence if exists myseq;\n",
    "create sequence myseq start 1 increment by 1 cache 1000;\n",
    "\n",
    "drop table if exists seq_crimes;\n",
    "create table seq_crimes as \n",
    "(select nextval('myseq'), year, description, count(*) total_crimes\n",
    "from crimes\n",
    "group by 2,3\n",
    "order by 1,2,3 desc\n",
    "limit 20);\n",
    "\n",
    "select * from seq_crimes order by 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists crimes_part;\n",
    "create table crimes_part (like crimes)\n",
    "distributed by (id)\n",
    "partition by list (primary_type)\n",
    "    (partition p1 values ('ROBBERY', 'BURGLARY'), \n",
    "     partition p2 values ('HOMOCIDE'), \n",
    "     default partition other);\n",
    "\n",
    "insert into crimes_part (select * from crimes);\n",
    "\n",
    "explain\n",
    "select a.*\n",
    "--from crimes a\n",
    "from crimes_part a\n",
    "where primary_type in ('HOMICIDE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query to see table sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT nspname || '.' || relname AS \"relation\", pg_size_pretty(pg_relation_size(C.oid)) \n",
    "AS \"size\" \n",
    "FROM pg_class C  \n",
    "LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace) \n",
    "WHERE nspname IN ('public', 'retail_demo') \n",
    "ORDER BY pg_relation_size(C.oid) DESC LIMIT 20;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect a BI tool to HAWQ\n",
    "\n",
    "### http://nbviewer.ipython.org/gist/catherinedevlin/6588378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Creating Custom Views for Table Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom view for table storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%% sql\n",
    "\n",
    "CREATE OR REPLACE VIEW public.v_gp_table_storage AS\n",
    "SELECT current_timestamp AS tms, n.nspname AS schema_name, c.relname AS table_name,\n",
    "        CASE\n",
    "            WHEN c.relstorage = 'a'::\"char\" THEN 'row append-only'::text\n",
    "            WHEN c.relstorage = 'c'::\"char\" THEN 'column append-only'::text\n",
    "            WHEN c.relstorage = 'h'::\"char\" THEN 'heap'::text\n",
    "            WHEN c.relstorage = 'x'::\"char\" THEN 'external'::text\n",
    "            ELSE NULL::text\n",
    "        END AS storage_type,\n",
    "              a.compresstype  AS compr_type,\n",
    "              a.compresslevel AS compr_level,\n",
    "              sotailtablesizedisk                                   as tabind_sz,\n",
    "              (sotailtablesizedisk         / 1024^3)::numeric(20,2) as tabind_sz_gb,\n",
    "              (sotailtablesizeuncompressed / 1024^3)::numeric(20,2) as tabind_sz_unc_gb,\n",
    "              case WHEN (sotailtablesizedisk=0 or sotailtablesizedisk is null) THEN -1 ELSE (sotailtablesizeuncompressed/sotailtablesizedisk)::numeric(6,1) END as compr_ratio\n",
    "              , c.relhassubclass as is_partitioned\n",
    "   FROM pg_class c\n",
    "   LEFT JOIN pg_appendonly a ON c.oid = a.relid\n",
    "   LEFT JOIN pg_namespace n ON n.oid = c.relnamespace\n",
    "   LEFT JOIN gp_toolkit.gp_size_of_table_and_indexes_licensing sot ON sot.sotailoid = c.oid\n",
    "  WHERE (n.nspname <> ALL (ARRAY['information_schema'::name, 'pg_catalog'::name, 'pg_toast'::name, 'gp_toolkit'::name])) AND c.relkind = 'r'::\"char\"\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another custom view for table storage.  Requires the first custom view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE OR REPLACE VIEW public.v_gp_table_storage2 AS\n",
    " SELECT tms,\n",
    "        schema_name,\n",
    "        regexp_replace(table_name::text, '_1_prt_.*$'::text, ''::text) AS table_name,\n",
    "              storage_type,\n",
    "              compr_type,\n",
    "              compr_level,\n",
    "              count(*)                            AS nr_of_partitions,\n",
    "              sum(tabind_sz)                      AS tabind_size,\n",
    "              sum(tabind_sz_gb)                   AS tabind_sz_gb,\n",
    "              sum(tabind_sz_unc_gb)               AS tabind_sz_unc_gb,\n",
    "              round(avg(compr_ratio)::numeric, 2) AS avg_compr_ratio\n",
    "   FROM public.v_gp_table_storage\n",
    "  WHERE storage_type <> 'external'::text AND table_name !~~ 'err_%'::text AND not is_partitioned\n",
    "  AND (COMPR_TYPE IS NOT NULL OR TABLE_NAME='crimes')\n",
    "  GROUP BY tms, schema_name, regexp_replace(table_name::text, '_1_prt_.*$'::text, ''::text), storage_type, compr_type, compr_level\n",
    "  ORDER BY 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B: Simple PL/PSQL Functions\n",
    "\n",
    "### Function that will apply logic based on user inputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "\n",
    "CREATE OR REPLACE FUNCTION myFunc (numtimes integer, msg text)\n",
    "  RETURNS text AS\n",
    "$BODY$\n",
    "DECLARE\n",
    "    strresult text;\n",
    "BEGIN\n",
    "    strresult := '';\n",
    "    IF numtimes = 1 THEN\n",
    "        strresult := 'Only one row!';\n",
    "    ELSIF numtimes > 0 AND numtimes < 11 THEN\n",
    "        FOR i IN 1 .. numtimes LOOP\n",
    "            strresult := strresult || msg || '; '; --E'\\r\\n';\n",
    "        END LOOP;\n",
    "    ELSE\n",
    "        strresult := 'You can not do that.';\n",
    "        IF numtimes <= 0 THEN\n",
    "            strresult := strresult || ' Must be greater than zero.';\n",
    "        ELSIF numtimes > 10 THEN\n",
    "            strresult := strresult || ' That''s too many items!';\n",
    "        END IF;\n",
    "    END IF;\n",
    "    RETURN strresult;\n",
    "END;\n",
    "$BODY$\n",
    "  LANGUAGE 'plpgsql' IMMUTABLE;\n",
    "ALTER FUNCTION myFunc(integer, text) OWNER TO gpadmin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that will build a date dimension when called with start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE OR REPLACE FUNCTION builddatedim(startdate date, enddate date)\n",
    "  RETURNS text AS\n",
    "$BODY$\n",
    "DECLARE\n",
    "    strresult text default ('Table Created!');\n",
    "    loopDate date default (startDate);\n",
    "BEGIN \n",
    "  execute 'drop table if exists dim_date';\n",
    "  execute 'create table dim_date (\n",
    "      date_key integer \n",
    "    , date_year smallint\n",
    "    , quarter_name char(2)\n",
    "    , year_quarter char(7)\n",
    "    , month_name varchar(15)\n",
    "    , month_name_short char(3)\n",
    "    , month_number smallint\n",
    "    , year_month varchar(7)\n",
    "    , date_value date\n",
    "    , day_name varchar(11)\n",
    "    , day_of_week_num smallint\n",
    "    , day_of_year smallint\n",
    "    , week_of_year smallint\n",
    "    , day_type varchar(10)\n",
    "    , date_formal varchar(20)\n",
    "    , last_30days_ind smallint\n",
    "    , last_60days_ind smallint\n",
    "    , last_90days_ind smallint\n",
    "    , rec_update_date date\n",
    "    ) distributed by (date_key)';\n",
    "  while loopDate <= endDate loop\n",
    "    execute 'insert into dim_date values (' ||\n",
    "             to_number(to_char(loopDate, 'yyyymmdd'), 99999999) || ', ' ||\n",
    "             extract(year from loopDate) || ', ' ||\n",
    "             '''Q' || extract(quarter from loopDate) || ''', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'yyyy')) || '-Q' || extract(quarter from loopDate) || ''', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'Month')) || ''', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'MON')) || ''', ' ||\n",
    "             to_number(to_char(loopDate, 'MM'), 99) || ', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'yyyy-MM')) || ''', ' ||\n",
    "             '''' || loopDate || ''', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'Day')) || ''', ' ||\n",
    "             extract(isodow from loopDate) || ', ' ||\n",
    "             to_number(to_char(loopDate, 'DDD'), 999) || ', ' ||\n",
    "             to_number(to_char(loopDate, 'WW'), 99) || ', ' ||\n",
    "             '''' || case when \n",
    "                       rtrim(to_char(loopDate, 'Day')) in ('Saturday', 'Sunday') then 'Weekend' else 'Weekday' \n",
    "                     end || ''', ' ||\n",
    "             '''' || rtrim(to_char(loopDate, 'FMMonth FMDDth, yyyy')) || ''', ' ||\n",
    "             case when \n",
    "               loopDate between (now()::date - interval '30 day') and now()::date then 1 else 0 \n",
    "             end || ', ' ||\n",
    "             case when \n",
    "               loopDate between (now()::date - interval '60 day') and now()::date then 1 else 0 \n",
    "             end || ', ' ||\n",
    "             case when \n",
    "               loopDate between (now()::date - interval '90 day') and now()::date then 1 else 0 \n",
    "             end || ', ' ||\n",
    "             '''' || now()::date || '''' ||\n",
    "             ')';\n",
    "    loopDate := loopDate + 1;\n",
    "\n",
    "  end loop;\n",
    "  RETURN strresult;\n",
    "END;\n",
    "$BODY$\n",
    "  LANGUAGE plpgsql VOLATILE;\n",
    "ALTER FUNCTION builddatedim(date, date)\n",
    "  OWNER TO gpadmin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that will build a time dimension when called with start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE OR REPLACE FUNCTION buildtimedim()\n",
    "  RETURNS text AS\n",
    "$BODY$\n",
    "DECLARE\n",
    "    strresult text default ('Table Created!');\n",
    "    loopTime time default ('0:00');\n",
    "BEGIN \n",
    "  execute 'drop table if exists dim_time';\n",
    "  execute 'create table dim_time (\n",
    "               time_key char(4)\n",
    "             , hour_minute time \n",
    "             , time_ampm varchar(8) \n",
    "             , hour_range_text varchar(20)\n",
    "             , day_segment varchar(20)\n",
    "            ) distributed by (time_key)';\n",
    "  for i in 0..1439 loop\n",
    "    execute 'insert into dim_time values (' ||\n",
    "             '''' || to_char(loopTime, 'hh24mi') || ''', ' ||\n",
    "             '''' || to_char(loopTime, 'hh24:mi') || ''', ' ||\n",
    "             '''' || to_char(loopTime, 'hh:miam') || ''', ' ||\n",
    "             '''' || case rtrim(to_char(loopTime, 'hh24')) \n",
    "                       when '00' then '12am-12:59am' when '01' then '1am-1:59am' when '02' then '2am-2:59am' \n",
    "                       when '03' then '3am-3:59am' when '04' then '4am-4:59am' when '05' then '5am-5:59am'\n",
    "                       when '06' then '6am-6:59am' when '07' then '7am-7:59am' when '08' then '8am-8:59am'\n",
    "                       when '09' then '9am-9:59am' when '10' then '10am-10:59am' when '11' then '11am-11:59am'\n",
    "                       when '12' then '12pm-12:59pm' when '13' then '1pm-1:59pm' when '14' then '2pm-2:59pm' \n",
    "                       when '15' then '3pm-3:59pm' when '16' then '4pm-4:59pm' when '17' then '5pm-5:59pm'\n",
    "                       when '18' then '6pm-6:59pm' when '19' then '7pm-7:59pm' when '20' then '8pm-8:59pm'\n",
    "                       when '21' then '9pm-9:59pm' when '22' then '10pm-10:59pm' when '23' then '11pm-11:59pm'\n",
    "                       else 'other' end || ''', ' ||\n",
    "             '''' || case  \n",
    "                       when rtrim(to_char(loopTime, 'hh24')) between  '00' and '04' then 'Late Night'\n",
    "                       when rtrim(to_char(loopTime, 'hh24')) between  '05' and '07' then 'Early Morning'\n",
    "                       when rtrim(to_char(loopTime, 'hh24')) between  '08' and '11' then 'Morning'\n",
    "                       when rtrim(to_char(loopTime, 'hh24')) between  '12' and '16' then 'Afternoon'\n",
    "                       when rtrim(to_char(loopTime, 'hh24')) between  '17' and '20' then 'Evening'\n",
    "                     else 'Night' end || '''' ||\n",
    "             ')';\n",
    "    loopTime := loopTime + interval '1 minute';\n",
    "  end loop;\n",
    "  RETURN strresult;\n",
    "END;\n",
    "$BODY$\n",
    "  LANGUAGE plpgsql VOLATILE;\n",
    "ALTER FUNCTION buildtimedim()\n",
    "  OWNER TO gpadmin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C:  Making the Crimes Data Larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "drop external table ext_crimes;\n",
    "create external table ext_crimes (like crimes) \n",
    "location ('gpfdist://mdw:8081/crimes-2001-present.csv') \n",
    "format 'csv' (header);\n",
    "\n",
    "-- NOTE:  EXECUTE THIS STATEMENT AS MANY TIMES AS NEEDED TO GET VOLUME REQUIRED.\n",
    "insert into crimes (select * from ext_crimes);  \n",
    "select count(*) total_records from crimes;\n",
    "\n",
    "drop external table if exists crimes_export;\n",
    "create writable external table crimes_export (like crimes)\n",
    "location ('gpfdist://mdw:8081/crimes_all.csv')\n",
    "format 'csv' (delimiter ',' null '');\n",
    "\n",
    "insert into crimes_export (select * from crimes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix D: Resource Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- in gp_toolkit schema\n",
    "-- gp_resq_priority_statement shows what's currently running\n",
    "-- gp_locks_on_resqueue\n",
    "\n",
    "\n",
    "-- QUEUE LIMITS\n",
    "alter role user1 with resource queue none;\n",
    "alter role user2 with resource queue none;\n",
    "drop role if exists user1;\n",
    "drop role if exists user2;\n",
    "\n",
    "-- create resource queue with 2 active statements\n",
    "drop resource queue q_activelimit;\n",
    "create resource queue q_activelimit with (active_statements = 3);\n",
    "\n",
    "-- create a user and assign them to a resource queue\n",
    "create role user1 with login password 'user1';\n",
    "alter user user1 with resource queue q_activelimit;\n",
    "alter user user1 set search_path to public, gp_toolkit;\n",
    "grant usage on schema public to user1;\n",
    "\n",
    "\n",
    "-- cat small_query, big query, active1-3\n",
    "-- active1.sh:  small query (7 secs)\n",
    "-- active2.sh:  (5) small query (15 secs)\n",
    "-- active3.sh   (10) small qeury (23 secs)\n",
    "-- active4.sh   (5) small query, but only 3 run at once (check views)\n",
    "\n",
    "--create resource queue based on cost.  Not used as frequently as its difficult to plan in ad hoc settings.\n",
    "--drop resource queue q_costlimit;\n",
    "--create resource queue q_costlimit with (max_cost=14e+6);  --14,000,000 cost limit\n",
    "\n",
    "-- create a user and assign them to a resource queue\n",
    "--create role user2 with login password 'user2';\n",
    "--alter user user2 with resource queue q_costlimit;\n",
    "--alter user user2 set search_path to public, gp_toolkit;\n",
    "--grant usage on schema public to user2;\n",
    "\n",
    "-- cost1.sh:    small query (7 secs) --show explain plan, only 1 can fit in the queue at once.\n",
    "-- cost2.sh:    (3) small query (runs one at a time)\n",
    "-- cost3.sh:    big query is beyond the cost limit, so you get error message\n",
    "\n",
    "-- QUEUE PRIORITIES\n",
    "create resource queue q_prioritymax with (active_statements=20, priority=max);\n",
    "create resource queue q_prioritymed with (active_statements=20, priority=medium);\n",
    "create resource queue q_prioritymin with (active_statements=20, priority=min);\n",
    "\n",
    "create role usermax with login password 'usermax';\n",
    "alter user usermax with resource queue q_prioritymax;\n",
    "alter user usermax set search_path to public, gp_toolkit;\n",
    "grant usage on schema public to usermax;\n",
    "\n",
    "create role usermed with login password 'usermed';\n",
    "alter user usermed with resource queue q_prioritymed;\n",
    "alter user usermed set search_path to public, gp_toolkit;\n",
    "grant usage on schema public to usermed;\n",
    "\n",
    "create role usermin with login password 'usermin';\n",
    "alter user usermin with resource queue q_prioritymin;\n",
    "alter user usermin set search_path to public, gp_toolkit;\n",
    "grant usage on schema public to usermin;\n",
    "\n",
    "-- sh pri1.sh  -- notice same run-time on each run\n",
    "-- sh pri2.sh  -- run same query on medium queue (note same timing regardless of queue)\n",
    "-- sh pri3.sh  -- same on max queue\n",
    "\n",
    "-- sh pri4.sh  -- run a mix of 3 med, 3 max;  max gets done faster; overall getting done faster (all small query)\n",
    "-- sh pri5.sh  -- run slow query on min queue, then check CC.  then launch pri4 again. (times wont' be affected)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "drop table if exists cms;\n",
    "CREATE TABLE cms\n",
    "(\n",
    "  car_line_id character varying(20),\n",
    "  bene_sex_ident_cd numeric(20),\n",
    "  bene_age_cat_cd bigint,\n",
    "  car_line_icd9_dgns_cd character varying(10),\n",
    "  car_line_hcpcs_cd character varying(10),\n",
    "  car_line_betos_cd character varying(5),\n",
    "  car_line_srvc_cnt bigint,\n",
    "  car_line_prvdr_type_cd bigint,\n",
    "  car_line_cms_type_srvc_cd character varying(5),\n",
    "  car_line_place_of_srvc_cd bigint,\n",
    "  car_hcpcs_pmt_amt bigint\n",
    ")\n",
    "distributed by (car_line_id);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
